# -*- coding: utf-8 -*-
"""DARPG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UwQ75sAR7IFBNXzj_FPuOARPJ5RTrUEV
"""

pip install joblib

import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
#from sklearn.externals import joblib
import joblib
from sklearn.pipeline import Pipeline
import numpy as np

# Step 1: Load and preprocess the grievance reports data
def load_data(file_path):
    # Load data from file
    data = pd.read_csv("/content/grievance_reports.csv")
    # Preprocess data if needed (e.g., remove stopwords, stemming, etc.)
    return data

# Step 2: Feature extraction using TF-IDF vectorization
def tfidf_vectorization(data):
    vectorizer = TfidfVectorizer(max_features=6, stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(data['text'])
    return tfidf_matrix, vectorizer

# Step 3: Model training - Clustering using KMeans
def train_model(tfidf_matrix, n_clusters=4):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(tfidf_matrix)
    return kmeans

# Step 4: Evaluate the model (optional)
def evaluate_model(tfidf_matrix, kmeans):
   silhouette_avg = silhouette_score(tfidf_matrix, kmeans.labels_)
   print("Silhouette Score:", silhouette_avg)

# Step 5: Save the model for future use
def save_model(model, model_path):
    joblib.dump(model, model_path)

# Step 6: Load the model
def load_model(model_path):
    model = joblib.load(model_path)
    return model

# Step 7: Predict cluster labels for new data
def predict_cluster(text, vectorizer, model):
    text_features = vectorizer.transform([text])
    predicted_cluster = model.predict(text_features)
    return predicted_cluster[0]

# Step 8: Define a function to share reports with last-mile officers
def share_reports(report, officers):
    # Code to share the report with officers
    pass

# Step 9: Main function to orchestrate the workflow
def main():
    # Step 1: Load data
    data = load_data('grievance_reports.csv')

    # Step 2: TF-IDF Vectorization
    tfidf_matrix, vectorizer = tfidf_vectorization(data)

    # Step 3: Model training
    kmeans_model = train_model(tfidf_matrix)

    # Step 4: Evaluate the model (optional)
    evaluate_model(tfidf_matrix, kmeans_model)

    # Step 5: Save the model
    save_model(kmeans_model, 'grievance_clustering_model.pkl')

    # Example: Predict cluster label for a new report
    new_report = "There is a pothole on Maple Ave. that needs to be fixed."
    predicted_cluster = predict_cluster(new_report, vectorizer, kmeans_model)
    print("Predicted Cluster:", predicted_cluster)

    # Step 8: Share reports with last-mile officers
    last_mile_officers = ['officer1@example.com', 'officer2@example.com']
    share_reports(new_report, last_mile_officers)

if __name__ == "__main__":
    main()